{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":157270322,"sourceType":"kernelVersion"}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --quiet snntorch tonic","metadata":{"_uuid":"aefb848c-9eca-420a-8253-1f89e66cac1b","_cell_guid":"5e8df514-dc4b-4dda-b2ed-00501d19c114","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-19T18:35:27.801077Z","iopub.execute_input":"2024-10-19T18:35:27.801386Z","iopub.status.idle":"2024-10-19T18:35:42.135971Z","shell.execute_reply.started":"2024-10-19T18:35:27.801353Z","shell.execute_reply":"2024-10-19T18:35:42.134666Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Importar librerias","metadata":{"_uuid":"c5efc959-558d-4f76-a962-61f7758a37dc","_cell_guid":"2f0d703b-9e36-42dd-950e-27694f126256","trusted":true}},{"cell_type":"code","source":"import tonic\nimport matplotlib.pyplot as plt\nfrom IPython.display import HTML\nimport torch\nimport torch.nn as nn\nimport snntorch as snn\nfrom snntorch import surrogate\nfrom snntorch import functional as SF\nfrom snntorch import utils\nimport time","metadata":{"_uuid":"04a111bb-3cb0-4259-8380-4a8aef2f63bc","_cell_guid":"02059bb1-31b8-4947-9176-515fd98153ab","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-19T18:49:29.150578Z","iopub.execute_input":"2024-10-19T18:49:29.151567Z","iopub.status.idle":"2024-10-19T18:49:41.399974Z","shell.execute_reply.started":"2024-10-19T18:49:29.151523Z","shell.execute_reply":"2024-10-19T18:49:41.398996Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Eventos a Frames","metadata":{}},{"cell_type":"code","source":"def to_frames(events):\n    frame_transform = tonic.transforms.ToFrame(\n        sensor_size=tonic.datasets.DVSGesture.sensor_size, \n        n_time_bins=100)\n    return frame_transform(events)","metadata":{"execution":{"iopub.status.busy":"2024-10-19T18:49:49.994111Z","iopub.execute_input":"2024-10-19T18:49:49.994609Z","iopub.status.idle":"2024-10-19T18:49:50.002169Z","shell.execute_reply.started":"2024-10-19T18:49:49.994571Z","shell.execute_reply":"2024-10-19T18:49:50.001191Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cargar Dataset","metadata":{"_uuid":"ce30df76-a1d0-4cef-ae86-2d2b4b8a7f86","_cell_guid":"279e7322-1a9b-4908-90ba-67f5fd894312","trusted":true}},{"cell_type":"code","source":"dataset_path = '/kaggle/input/create-dvs128gesture-tonic-dataset'\ntrain = tonic.datasets.DVSGesture(save_to=dataset_path, train=True)\ntest = tonic.datasets.DVSGesture(save_to=dataset_path, train=False)\nframes, label = train[2]\nframes = to_frames(frames)\nani = tonic.utils.plot_animation(frames)\nHTML(ani.to_jshtml())","metadata":{"_uuid":"6749871d-106b-4f7c-8925-57bf0fc3b272","_cell_guid":"7e5a5593-f6a3-4285-818b-742632acac45","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-19T18:49:58.646884Z","iopub.execute_input":"2024-10-19T18:49:58.647242Z","iopub.status.idle":"2024-10-19T18:50:02.576791Z","shell.execute_reply.started":"2024-10-19T18:49:58.647207Z","shell.execute_reply":"2024-10-19T18:50:02.575920Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Aplicar transformaciones al dataset","metadata":{"_uuid":"bc6c0fbb-c030-41aa-b4a6-4c0f76a83cc9","_cell_guid":"fd3ac519-9c1c-4419-a536-dceb23fd2eca","trusted":true}},{"cell_type":"code","source":"w,h=32,32\nn_frames=32 #100\n\ndebug = False\n\ntransforms = tonic.transforms.Compose([\n    tonic.transforms.Denoise(filter_time=10000), \n    tonic.transforms.Downsample(sensor_size=tonic.datasets.DVSGesture.sensor_size, target_size=(w,h)), \n    tonic.transforms.ToFrame(sensor_size=(w,h,2), n_time_bins=n_frames), \n])\n\ntrain2 = tonic.datasets.DVSGesture(save_to=dataset_path, transform=transforms, train=True)\ntest2 = tonic.datasets.DVSGesture(save_to=dataset_path, transform=transforms, train=False)\n\ncached_train = tonic.DiskCachedDataset(train2, cache_path='/temp/dvsgesture/train')\ncached_test = tonic.DiskCachedDataset(test2, cache_path='/temp/dvsgesture/test')\n\nframes, label = train2[2]\nani = tonic.utils.plot_animation(frames)\nHTML(ani.to_jshtml())","metadata":{"_uuid":"bb793643-0f62-4571-8ed1-3e4044265347","_cell_guid":"ffff6bef-8eef-4ee1-9547-5febd55486b5","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-19T20:00:37.831331Z","iopub.execute_input":"2024-10-19T20:00:37.832130Z","iopub.status.idle":"2024-10-19T20:00:42.005573Z","shell.execute_reply.started":"2024-10-19T20:00:37.832086Z","shell.execute_reply":"2024-10-19T20:00:42.004738Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Configuración de GPU","metadata":{"_uuid":"cfa97f39-bdc1-4542-9b16-9d3c850fc4ab","_cell_guid":"201dd843-bf92-4bc1-a0df-aa187c744d17","trusted":true}},{"cell_type":"code","source":"device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nif torch.cuda.is_available():\n    print(f\"GPUs Available: {torch.cuda.device_count()}\")","metadata":{"_uuid":"98dd61f5-f977-4770-858f-47a5dba42799","_cell_guid":"808a8e70-b688-492e-99a8-4d26f403ecfc","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-19T18:50:26.560130Z","iopub.execute_input":"2024-10-19T18:50:26.560763Z","iopub.status.idle":"2024-10-19T18:50:26.632655Z","shell.execute_reply.started":"2024-10-19T18:50:26.560724Z","shell.execute_reply":"2024-10-19T18:50:26.631828Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Arquitectura de Red","metadata":{"_uuid":"ad940ea6-fbe9-4e1f-91fa-af1c0ea53863","_cell_guid":"646632da-6d67-4de8-82d9-45ea89ba36e3","trusted":true}},{"cell_type":"code","source":"grad = snn.surrogate.fast_sigmoid(slope=25) # surrogate.atan()\nbeta = 0.5\n\nnet = nn.Sequential(\n    nn.Conv2d(2, 12, 5), # in_channels, out_channels, kernel_size\n    nn.MaxPool2d(2),\n    snn.Leaky(beta=beta, spike_grad=grad, init_hidden=True),\n    nn.Conv2d(12, 32, 5),\n    nn.MaxPool2d(2),\n    snn.Leaky(beta=beta, spike_grad=grad, init_hidden=True),\n    nn.Flatten(),\n    nn.Linear(800, 11), #800\n    snn.Leaky(beta=beta, spike_grad=grad, init_hidden=True, output=True)\n).to(device)\n\ndef forward_pass(net, data):\n    spk_rec = []\n    snn.utils.reset(net)  \n    for step in range(data.size(0)): \n        spk_out, mem_out = net(data[step])\n        spk_rec.append(spk_out)\n    return torch.stack(spk_rec)\n\noptimizer = torch.optim.Adam(net.parameters(), lr=0.002, betas=(0.9, 0.999))\nloss_fn = SF.mse_count_loss(correct_rate=0.8, incorrect_rate=0.2)\n\nloss_hist = []\nacc_hist = []\ntest_acc_hist = []","metadata":{"_uuid":"dee84a92-8cd5-4060-bfe3-b015f17d1fcd","_cell_guid":"9b5966ff-7a6a-4ad3-8879-af01c3fe56d3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-19T20:12:02.405690Z","iopub.execute_input":"2024-10-19T20:12:02.406554Z","iopub.status.idle":"2024-10-19T20:12:02.420275Z","shell.execute_reply.started":"2024-10-19T20:12:02.406510Z","shell.execute_reply":"2024-10-19T20:12:02.419362Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Validación del modelo","metadata":{"_uuid":"0a264013-28b1-46d9-ac1c-16777c3cfc02","_cell_guid":"20f586ba-eee1-4101-b2ba-545dfb2fcaa7","trusted":true}},{"cell_type":"code","source":"def validate_model():\n    correct, total = 0, 0  \n    for batch, (data, targets) in enumerate(iter(test_loader)): \n        data, targets = data.to(device), targets.to(device)\n        spk_rec = forward_pass(net, data)         \n        correct += SF.accuracy_rate(spk_rec, targets) * data.shape[0]\n        total += data.shape[0]\n    return correct/total","metadata":{"_uuid":"e3f5f658-b4f5-417c-a305-348f4037b811","_cell_guid":"04e890c2-35b0-4561-ae49-92306a094fd8","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-19T18:50:32.641971Z","iopub.execute_input":"2024-10-19T18:50:32.642928Z","iopub.status.idle":"2024-10-19T18:50:32.648627Z","shell.execute_reply.started":"2024-10-19T18:50:32.642889Z","shell.execute_reply":"2024-10-19T18:50:32.647705Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_loader = torch.utils.data.DataLoader(cached_train, batch_size=64, shuffle=True, drop_last=True, \n                                           collate_fn=tonic.collation.PadTensors(batch_first=False))\ntest_loader = torch.utils.data.DataLoader(cached_test, batch_size=32, shuffle=False, drop_last=True, \n                                          collate_fn=tonic.collation.PadTensors(batch_first=False))","metadata":{"_uuid":"09ea5b06-a946-4220-bd3e-d5335907259e","_cell_guid":"7fe77d2f-493d-47a3-8c84-7d4ba1b4a78a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-19T18:50:35.088879Z","iopub.execute_input":"2024-10-19T18:50:35.089247Z","iopub.status.idle":"2024-10-19T18:50:35.095186Z","shell.execute_reply.started":"2024-10-19T18:50:35.089209Z","shell.execute_reply":"2024-10-19T18:50:35.094134Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"start_time = time.time()\nbest_acc = 0.0\nnum_epochs = 400\ncnt = 0\n\nfor epoch in range(num_epochs):\n    for batch, (data, targets) in enumerate(iter(train_loader)):\n        data = data.to(device)\n        data = data.float()\n        targets = targets.to(device)\n        net.train()\n        \n        spk_rec = forward_pass(net, data)\n        loss = loss_fn(spk_rec, targets)\n\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        \n        loss_hist.append(loss.item())\n\n        acc = SF.accuracy_rate(spk_rec, targets)\n        acc_hist.append(acc)\n\n        if cnt % 50 == 0:\n            print(f\"Epoch {epoch}, Iteration {batch} \\nTrain Loss: {loss.item():.2f}\")\n            print(f\"Train Accuracy: {SF.accuracy_rate(spk_rec, targets) * 100:.2f}%\")\n            test_acc = validate_model()\n            test_acc_hist.append(test_acc)\n            print(f\"Test Accuracy: {test_acc * 100:.2f}%\\n\")\n            \n            if test_acc > best_acc:\n                print(f\"New best model found! Saving model at epoch {epoch} with accuracy {test_acc * 100:.2f}%\")\n                best_acc = test_acc\n                torch.save({\n                    'epoch': epoch,\n                    'model_state_dict': net.state_dict(),\n                    'optimizer_state_dict': optimizer.state_dict(),\n                    'best_acc': best_acc,\n                    'loss': loss.item(),\n                }, \"best_model.pth\")\n\n        cnt+=1\n\nend_time = time.time()\n\n\nelapsed_time = end_time - start_time\n\n\nminutes, seconds = divmod(elapsed_time, 60)\nseconds, milliseconds = divmod(seconds, 1)\nmilliseconds = round(milliseconds * 1000)\n\n\nprint(f\"Elapsed time: {int(minutes)} minutes, {int(seconds)} seconds, {milliseconds} milliseconds\")","metadata":{"_uuid":"1aade5f3-d2a9-45bd-928a-f6f0baf2333a","_cell_guid":"17d0afd0-ee7d-4ddc-b621-4ac9f04528b5","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-19T20:21:08.367860Z","iopub.execute_input":"2024-10-19T20:21:08.368214Z","iopub.status.idle":"2024-10-19T20:42:12.302232Z","shell.execute_reply.started":"2024-10-19T20:21:08.368179Z","shell.execute_reply":"2024-10-19T20:42:12.301239Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 3, figsize=(18,4))\n\n# Plot Train Accuracy\naxes[0].plot(acc_hist)\naxes[0].set_title(\"Train Set Accuracy\")\naxes[0].set_xlabel(\"Iteration\")\naxes[0].set_ylabel(\"Accuracy\")\n\n# Plot Test Accuracy\naxes[1].plot(test_acc_hist)\naxes[1].set_title(\"Test Set Accuracy\")\naxes[1].set_xlabel(\"Iteration\")\naxes[1].set_ylabel(\"Accuracy\")\n\n# Plot Training Loss\naxes[2].plot(loss_hist)\naxes[2].set_title(\"Loss History\")\naxes[2].set_xlabel(\"Iteration\")\naxes[2].set_ylabel(\"Loss\")\n\nplt.show()","metadata":{"_uuid":"b7ccae6c-bf18-4130-872a-730af1f1496d","_cell_guid":"e55dbcf6-f9e3-40d9-aaff-c301498d0a80","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def to_frames(events):\n     \n    frame_transform = tonic.transforms.ToFrame(\n        sensor_size=tonic.datasets.DVSGesture.sensor_size, \n        n_time_bins=100)\n    return frame_transform(events)","metadata":{"_uuid":"3a4a51ff-393f-47a7-a607-c8784fb96ee2","_cell_guid":"ee7d40c2-eb59-4f1b-9544-a5785dba6551","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cargar el modelo entrenado","metadata":{"_uuid":"e82a200a-b010-4e9d-9bee-792566da3415","_cell_guid":"fc2c56ea-e433-47ce-b76c-370380e510cb","trusted":true}},{"cell_type":"code","source":"model_path = \"/kaggle/working/best_model.pth\" \ncheckpoint = torch.load(model_path, weights_only=False)\nnet.load_state_dict(checkpoint['model_state_dict'])\nnet.eval() ","metadata":{"_uuid":"68558b4e-a72d-4893-a61c-a384814fa635","_cell_guid":"f579433e-7bee-4b05-8c94-f8b657d5ff69","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Inferencia de solo texto","metadata":{}},{"cell_type":"code","source":"# Obtener un DataLoader para el conjunto de prueba\ntest_loader = torch.utils.data.DataLoader(cached_test, batch_size=1, shuffle=True, drop_last=True,\n                                         collate_fn=tonic.collation.PadTensors(batch_first=False),)\n\n# Lista para almacenar las predicciones y etiquetas correctas\npredictions = []\ntrue_labels = []\nindices = []\n\n# Realizar 4 inferencias aleatorias\nfor i in range(4):\n    # Obtener un batch aleatorio del conjunto de prueba\n    data, target = next(iter(test_loader))\n    data = data.to(device)\n    target = target.to(device)\n  \n    # Realizar la inferencia\n    \n    spk_rec = forward_pass(net, data)\n    \n    predicted_label = torch.argmax(spk_rec.sum(dim=0), dim=1).item()\n\n    # Almacenar la predicción y la etiqueta correcta\n    predictions.append(predicted_label)\n    true_labels.append(target.item())\n    \n# Imprimir los resultados\nfor pred, true in zip(predictions, true_labels):\n    print(f\"Predicción: {pred+1}, Etiqueta correcta: {true+1}\")\n    \n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Inferencia con texto y video","metadata":{}},{"cell_type":"code","source":"\n# Obtener un DataLoader para el conjunto de prueba\ntest_loader = torch.utils.data.DataLoader(cached_test, batch_size=1, shuffle=True, drop_last=True,\n                                         collate_fn=tonic.collation.PadTensors(batch_first=False),)\n\n\n# Lista para almacenar las predicciones y etiquetas correctas\npredictions = []\ntrue_labels = []\n\n\nfor i in range(4):\n    data, target = next(iter(test_loader))\n    data = data.to(device)\n    target = target.to(device)\n    \n   \n    # Suponiendo que data tiene la forma (num_frames, height, width, channels)\n    frames = data[:, 0, ...].cpu()\n    ani = tonic.utils.plot_animation(frames)\n    display(HTML(ani.to_jshtml()))\n\n    \n    spk_rec = forward_pass(net, data)\n    predicted_label = torch.argmax(spk_rec.sum(dim=0), dim=1).item()\n    \n    # Realizar la inferencia\n    # ... (tu código para realizar la inferencia)\n    predictions.append(predicted_label)\n    true_labels.append(target.item())\n    print(f\"Valor predicho: {predicted_label+1}, Etiqueta correcta: {target.item()+1}\")\n\n\n# Imprimir los resultados\nfor pred, true in zip(predictions, true_labels):\n    print(f\"Predicción: {pred+1}, Etiqueta correcta: {true+1}\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Obtener un DataLoader para el conjunto de prueba\ntest_loader = torch.utils.data.DataLoader(cached_test, batch_size=1, shuffle=True, drop_last=True,\n                                         collate_fn=tonic.collation.PadTensors(batch_first=False),)\n\n# Lista para almacenar las predicciones y etiquetas correctas\npredictions = []\ntrue_labels = []\nindices = []\n\n# Realizar 4 inferencias aleatorias\nfor i in range(4):\n    # Obtener un batch aleatorio del conjunto de prueba\n    data, target = next(iter(test_loader))\n    data = data.to(device)\n    target = target.to(device)\n  \n    # Realizar la inferencia\n    \n    spk_rec = forward_pass(net, data)\n    \n    predicted_label = torch.argmax(spk_rec.sum(dim=0), dim=1).item()\n\n    # Almacenar la predicción y la etiqueta correcta\n    predictions.append(predicted_label)\n    true_labels.append(target.item())\n    \n# Imprimir los resultados\nfor pred, true in zip(predictions, true_labels):\n    print(f\"Predicción: {pred+1}, Etiqueta correcta: {true+1}\")\n    \n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport matplotlib.pyplot as plt\nimport snntorch as snn\n\ndef forward_pass2(net, data):\n    spk_rec = []\n    mem_rec = []  # Lista para registrar el potencial de membrana en cada paso\n    snn.utils.reset(net)  # Resetea los estados internos de las neuronas (importante para secuencias)\n    \n    for step in range(data.size(0)):  # data.size(0) es el número de pasos temporales\n        spk_out, mem_out = net(data[step])  # Obtener los spikes y el potencial de membrana\n        spk_rec.append(spk_out)\n        mem_rec.append(mem_out)  # Almacenar el potencial de membrana\n    \n    return torch.stack(spk_rec), torch.stack(mem_rec)\n\n# Obtener un DataLoader para el conjunto de prueba\ntest_loader = torch.utils.data.DataLoader(cached_test, batch_size=1, shuffle=True, drop_last=True,\n                                          collate_fn=tonic.collation.PadTensors(batch_first=False),)\n\nfor i in range(4):  # Realizar 4 inferencias aleatorias\n    data, target = next(iter(test_loader))\n    data = data.to(device)\n    target = target.to(device)\n\n    # Realizar la inferencia\n    spk_rec, mem_rec = forward_pass2(net, data)\n\n    # Crear un subplot para el potencial de membrana\n    plt.figure(figsize=(10, 6))\n\n    # Graficar el potencial de membrana (mem_rec)\n    neuron_count = mem_rec.size(1)  # Número de neuronas\n    for neuron in range(neuron_count):  # Iterar sobre las neuronas\n        plt.plot(mem_rec[:, neuron].detach().cpu().numpy())  # Graficar cada neurona sin leyenda\n\n    plt.title(f\"Potencial de Membrana durante la Inferencia {i+1}\")\n    plt.xlabel(\"Tiempo\")\n    plt.ylabel(\"Potencial de Membrana\")\n    plt.tight_layout()\n    plt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport matplotlib.pyplot as plt\nimport snntorch as snn\nfrom IPython.display import HTML, display\n\ndef forward_pass2(net, data):\n    spk_rec = []\n    mem_rec = []  # Lista para registrar el potencial de membrana en cada paso\n    snn.utils.reset(net)  # Resetea los estados internos de las neuronas (importante para secuencias)\n    \n    for step in range(data.size(0)):  # data.size(0) es el número de pasos temporales\n        spk_out, mem_out = net(data[step])  # Obtener los spikes y el potencial de membrana\n        spk_rec.append(spk_out)\n        mem_rec.append(mem_out)  # Almacenar el potencial de membrana\n    \n    return torch.stack(spk_rec), torch.stack(mem_rec)\n\n# Obtener un DataLoader para el conjunto de prueba\ntest_loader = torch.utils.data.DataLoader(cached_test, batch_size=1, shuffle=True, drop_last=True,\n                                          collate_fn=tonic.collation.PadTensors(batch_first=False),)\n\n# Lista para almacenar las predicciones y etiquetas correctas\npredictions = []\ntrue_labels = []\n\nfor i in range(4):  # Realizar 4 inferencias aleatorias\n    data, target = next(iter(test_loader))\n    data = data.to(device)\n    target = target.to(device)\n    \n    # Suponiendo que data tiene la forma (num_frames, height, width, channels)\n    frames = data[:, 0, ...].cpu()\n    ani = tonic.utils.plot_animation(frames)\n    display(HTML(ani.to_jshtml()))\n\n    # Realizar la inferencia\n    spk_rec, mem_rec = forward_pass2(net, data)\n    \n    # Obtener la etiqueta predicha\n    predicted_label = torch.argmax(spk_rec.sum(dim=0), dim=1).item()\n    \n    # Almacenar la predicción y la etiqueta correcta\n    predictions.append(predicted_label)\n    true_labels.append(target.item())\n    \n    print(f\"Valor predicho: {predicted_label + 1}, Etiqueta correcta: {target.item() + 1}\")\n\n    # Crear un subplot para el potencial de membrana\n    plt.figure(figsize=(10, 6))\n\n    # Graficar el potencial de membrana (mem_rec)\n    neuron_count = mem_rec.size(1)  # Número de neuronas\n    for neuron in range(neuron_count):  # Iterar sobre las neuronas\n        plt.plot(mem_rec[:, neuron].detach().cpu().numpy())  # Graficar cada neurona sin leyenda\n\n    plt.title(f\"Potencial de Membrana durante la Inferencia {i + 1}\")\n    plt.xlabel(\"Tiempo\")\n    plt.ylabel(\"Potencial de Membrana\")\n    plt.tight_layout()\n    plt.show()\n\n# Imprimir los resultados finales\nfor pred, true in zip(predictions, true_labels):\n    print(f\"Predicción: {pred + 1}, Etiqueta correcta: {true + 1}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport matplotlib.pyplot as plt\nimport snntorch as snn\nfrom IPython.display import HTML, display\n\ndef forward_pass2(net, data):\n    spk_rec = []\n    mem_rec = []  # Lista para registrar el potencial de membrana en cada paso\n    snn.utils.reset(net)  # Resetea los estados internos de las neuronas (importante para secuencias)\n    \n    for step in range(data.size(0)):  # data.size(0) es el número de pasos temporales\n        spk_out, mem_out = net(data[step])  # Obtener los spikes y el potencial de membrana\n        spk_rec.append(spk_out)  # Asegúrate de que spk_out tenga la forma correcta\n        mem_rec.append(mem_out)  # Almacenar el potencial de membrana\n    \n    return torch.stack(spk_rec), torch.stack(mem_rec)\n\n# Obtener un DataLoader para el conjunto de prueba\ntest_loader = torch.utils.data.DataLoader(cached_test, batch_size=1, shuffle=True, drop_last=True,\n                                          collate_fn=tonic.collation.PadTensors(batch_first=False),)\n\n# Lista para almacenar las predicciones y etiquetas correctas\npredictions = []\ntrue_labels = []\n\n# Lista de etiquetas para el gráfico de conteo de picos\nlabels = ['1', '2', '3', '4', '5', '6', '7', '8','9', '10', '11']  # Cambiar según el número de clases\n\nfor i in range(4):  # Realizar 4 inferencias aleatorias\n    data, target = next(iter(test_loader))\n    data = data.to(device)\n    target = target.to(device)\n\n    # Verificar si los datos están bien\n    print(f\"Data shape: {data.shape}, Target: {target}\")\n\n    # Suponiendo que data tiene la forma (num_frames, height, width, channels)\n    frames = data[:, 0, ...].cpu()\n    ani = tonic.utils.plot_animation(frames)\n    display(HTML(ani.to_jshtml()))\n\n    # Realizar la inferencia\n    spk_rec, mem_rec = forward_pass2(net, data)\n\n    # Verificar si spk_rec tiene datos\n    print(f\"spk_rec shape: {spk_rec.shape}\")\n\n    # Obtener la etiqueta predicha\n    predicted_label = torch.argmax(spk_rec.sum(dim=0), dim=1).item()\n\n    # Almacenar la predicción y la etiqueta correcta\n    predictions.append(predicted_label)\n    true_labels.append(target.item())\n\n    print(f\"Valor predicho: {predicted_label + 1}, Etiqueta correcta: {target.item() + 1}\")\n\n    # Crear un subplot para el potencial de membrana\n    plt.figure(figsize=(10, 6))\n\n    # Graficar el potencial de membrana (mem_rec)\n    neuron_count = mem_rec.size(1)  # Número de neuronas\n    for neuron in range(neuron_count):  # Iterar sobre las neuronas\n        plt.plot(mem_rec[:, neuron].detach().cpu().numpy())  # Graficar cada neurona sin leyenda\n\n    plt.title(f\"Potencial de Membrana durante la Inferencia {i + 1}\")\n    plt.xlabel(\"Tiempo\")\n    plt.ylabel(\"Potencial de Membrana\")\n    plt.tight_layout()\n    plt.show()\n\n    # Graficar el conteo de picos (spike count) para la etiqueta objetivo\n    idx = target.item()  # Obtener la etiqueta objetivo como un entero\n    if idx < spk_rec.size(1):  # Verificar que el índice esté dentro de los límites\n        fig, ax = plt.subplots(facecolor='w', figsize=(12, 7))\n        print(f\"La etiqueta objetivo es: {target.item()}\")\n\n        # Graficar el histograma de conteo de picos\n        anim = splt.spike_count(spk_rec[:, 0].detach().cpu(), fig, ax, labels=labels,  # Cambiar a [0] para tomar el primer spike\n                                animate=True, interpolate=1)\n\n        display(HTML(anim.to_html5_video()))\n    else:\n        print(f\"Índice {idx} fuera de los límites de spk_rec (tamaño: {spk_rec.size(1)})\")\n\n# Imprimir los resultados finales\nfor pred, true in zip(predictions, true_labels):\n    print(f\"Predicción: {pred + 1}, Etiqueta correcta: {true + 1}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}